# Edge SLM Benchmark - Performance Scenarios Configuration
# Performance benchmark scenarios definition

# Global execution protocol
protocol:
  warmup_runs: 3          # Warm-up requests (not counted)
  benchmark_runs: 20      # Number of runs per scenario
  cooldown_seconds: 2     # Pause between runs
  
  # Execution conditions
  execution_conditions:
    - "Machine plugged into power"
    - "Power saving mode disabled"
    - "Heavy applications closed (browser, secondary IDEs)"
    - "Stable ambient temperature (~20-25Â°C)"

# Metrics to collect for all scenarios
metrics:
  timing:
    - ttft_ms           # Time To First Token (ms)
    - total_time_ms     # Total generation time (ms)
  throughput:
    - output_tokens_per_sec   # Generation throughput
    - prompt_tokens_per_sec   # Prompt ingestion speed
  memory:
    - peak_ram_mb       # Maximum RAM used
    - avg_ram_mb        # Average RAM during generation
  statistics:
    - mean
    - std
    - p50
    - p95
    - min
    - max

# === PERFORMANCE SCENARIOS ===
scenarios:
  # Scenario 1: Interactive Assistant
  interactive_assistant:
    name: "Interactive Assistant"
    description: "Simulation of a banking assistant answering short questions"
    category: "latency_sensitive"
    
    parameters:
      input_tokens_range: [200, 400]
      output_tokens: 128
      max_tokens: 128
      
    metrics_focus:
      - ttft_ms           # Critical for interactive UX
      - output_tokens_per_sec
      
    prompts_file: "prompts/interactive_assistant.yaml"
    
    # Quality thresholds (indicative)
    quality_thresholds:
      ttft_ms_max: 500      # < 500ms for good UX
      tokens_per_sec_min: 20

  # Scenario 2: Long-form Summary
  long_form_summarization:
    name: "Long-form Summarization"
    description: "Summary of long documents (reports, internal notes)"
    category: "throughput_sensitive"
    
    parameters:
      input_tokens_range: [2000, 4000]
      output_tokens_range: [256, 512]
      max_tokens: 512
      
    metrics_focus:
      - output_tokens_per_sec
      - peak_ram_mb
      - total_time_ms
      
    prompts_file: "prompts/summarization.yaml"
    
    quality_thresholds:
      tokens_per_sec_min: 15
      peak_ram_mb_max: 12000  # 12GB pour laptop 16GB

  # Scenario 3: Structured JSON Output
  structured_json_output:
    name: "Structured JSON Output"
    description: "Information extraction with constrained JSON output"
    category: "reliability_sensitive"
    
    parameters:
      input_tokens_range: [500, 1000]
      output_tokens_range: [100, 300]
      max_tokens: 300
      use_structured_output: true
      
    metrics_focus:
      - json_valid_rate     # Valid JSON rate
      - output_tokens_per_sec
      - ttft_ms
      
    prompts_file: "prompts/json_extraction.yaml"
    
    quality_thresholds:
      json_valid_rate_min: 0.95   # Minimum 95% valid JSONs
      tokens_per_sec_min: 15

# === REALISTIC BANKING SCENARIOS ===
realistic_scenarios:
  # Banking FAQ
  banking_faq:
    name: "Banking FAQ Assistant"
    description: "Answers to common customer questions about banking services"
    category: "interactive"
    
    parameters:
      input_tokens_range: [100, 300]
      output_tokens: 200
      max_tokens: 200
      
    evaluation:
      - response_relevance
      - factual_accuracy
      - response_time
      
    prompts_file: "prompts/banking_faq.yaml"

  # Sentiment Analysis
  sentiment_analysis:
    name: "Customer Feedback Sentiment"
    description: "Sentiment classification on customer feedback"
    category: "classification"
    
    parameters:
      input_tokens_range: [50, 200]
      output_tokens: 50
      max_tokens: 50
      
    evaluation:
      - accuracy
      - macro_f1
      - confusion_matrix
      
    prompts_file: "prompts/sentiment.yaml"

  # Information Extraction
  info_extraction:
    name: "Document Information Extraction"
    description: "Structured information extraction from documents"
    category: "extraction"
    
    parameters:
      input_tokens_range: [300, 800]
      output_tokens: 200
      max_tokens: 200
      use_structured_output: true
      
    evaluation:
      - field_accuracy
      - json_valid_rate
      - extraction_completeness
      
    prompts_file: "prompts/extraction.yaml"

  # Document Summary
  document_summary:
    name: "Internal Document Summary"
    description: "Synthesis of reports and internal notes"
    category: "generation"
    
    parameters:
      input_tokens_range: [1000, 3000]
      output_tokens: 300
      max_tokens: 300
      
    evaluation:
      - rouge_scores
      - key_info_coverage
      - coherence
      
    prompts_file: "prompts/document_summary.yaml"


